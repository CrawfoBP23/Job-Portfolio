# Reflection Questions

Answer these questions thoroughly, using examples from your code. Good answers will be 1-2 paragraphs that cite specific code examples and show a meaningful reflection on how your development went, and how it could be improved in the future.

## Question 1

In part 2, you now have to support two different inputs, CSV and XLSX. Imagine we asked you to also support reading in another file format, such as JSON. How much code would you need to add/change to enable this? Cite specific existing functions/classes that would need to change.

## Answer

The current readFile method (in the ReadFile class) accepts a string input as a filepath and uses if-else statements to determine file type and call the respective method, readCSV or readExcel, or throw an invalid file error. The method returns an ArrayList of DataObjs that contain state names, populations, and empty fields for representatives and remainder. The original code, from Part 1, was just one method, ReadCSV. We didn't want to delete a lot of code and it felt messy to wrap everything in a bunch of if-statements. Instead, we made a general readFile method to determine the file type and call their respective method. This allowed us to reuse the majority of the code from readCSV while still keeping the Main class neat and readable. Another advantage of the current setup is that adding more file formats would not be overly complicated. Only the ReadFile class would change, the other classes (including Main) would not be affected. In the ReadFile class, the readFile method would have another else if clause checking if the file ends with ".json" to call readJSON, and there would be an additional method in the readFile method called readJSON that would handle reading in the JSON file. 

An additional aspect that we considered at the end of the development process was whether or not the readExcel file was even necessary. Towards the end of the development process, we had trouble creating the fat jar with the Apache POI dependencies included. While we were ultimately able to resolve this issue, it led to the consideration of how we could accomplish the task without the Apache POI library. For example, instead of reading and parsing the Excel sheet, what if we just had a function to convert it into a CSV file? The method would check the file type, and if it was an excel sheet, it would call convertToCSV. Then, we'd call readCSV on the resultant file. While this method seemed appealing in the moment, ultimately we believe that our method is superior. The convertToCSV method would have to parse through the Excel sheet anyways, meaning that we would still need to import the Apache POI library. Additionally, this would double the run time of Excel files. The program would iterate through the file once to convert it into a CSV and then iterate through it again to pass the data to the Main method, whereas the current strategy is to iterate through once to pass the data directly to the Main method. This alternative idea of conversion to CSV would also be inefficient for processing new file types as well. The same double iteration would occur to first convert the data to CSV and then process the CSV data, and it wouldn't be more efficient in terms of writing the code compared to our original method. 

## Question 2

Looking back, which part was more difficult? Part 1, where you had to start from scratch, or Part 2, where you had to change existing code. Explain your answer, citing any specific challenges. In hindsight, would you do anything differently?

## Answer

With respect to the main method, it was more difficult in part 1 starting from scratch to create all variables and conditional statements from scratch. Part 2 only required adding a few more throws for exception handling and some added conditional statements as well. For example, I created the variable boolean hillDefault, which was updated through conditionals checking if the second argument or third argument ever equaled --hamilton . It was much quicker to implement these with the structure already built earlier since I could wrap an if statement checking for the hamilton keyword and then putting the file-handling instructions originally built in part 1 in the corresponding else statement. The bigger challenge with the main method in part 2 was just making sure the exception for the Huntington-Hill algorithm was thrown and caught correctly, but this just necessitated one more conditional within the already existing try-catch block built in part 1. This made the process of file-handling and managing the exceptions much easier in part 2 compared to part 1.   

Part 1 was also more difficult because it required designing the entire logic from scratch, including calculating initial representatives using assignInitialReps(), where double quotient = state.getPop() / totalAvg; int floor = (int) quotient; ensured correct rounding, and handling remainder-based allocations in allocateRemainingReps(), where if (highestRem != null) { highestRem.setRep(highestRem.getRep() + 1); visitedStates.remove(highestRem); } distributed leftover representatives. Debugging was challenging due to type casting and rounding errors. In contrast, Part 2 involved modifying existing logic, where the main challenge was implementing calculatePriority(), which used return state.getPop() / Math.sqrt(n * (n + 1)); to calculate priority scores correctly, and iterating in apportion(), where if (priority > maxPriority) { maxPriority = priority; highestPriorityState = state; } ensured representatives were assigned efficiently. While Part 2 required careful adjustments, the structural foundation made it easier than starting from scratch. In hindsight, I would plan the algorithm more thoroughly in Part 1 and use a priority queue in Part 2 to improve efficiency. Adding robust unit tests earlier in both cases would have helped catch edge cases more efficiently.
